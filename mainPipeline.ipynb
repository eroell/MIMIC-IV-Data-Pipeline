{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b16d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "available-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "\n",
    "module_path='preprocessing/day_intervals_preproc'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path='utils'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "module_path='preprocessing/hosp_module_preproc'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "module_path='model'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#print(sys.path)\n",
    "root_dir = os.path.dirname(os.path.abspath('UserInterface.ipynb'))\n",
    "import day_intervals_cohort\n",
    "from day_intervals_cohort import *\n",
    "\n",
    "import day_intervals_cohort_v2\n",
    "from day_intervals_cohort_v2 import *\n",
    "\n",
    "import data_generation_icu\n",
    "\n",
    "import data_generation\n",
    "import evaluation\n",
    "\n",
    "import feature_selection_hosp\n",
    "from feature_selection_hosp import *\n",
    "\n",
    "# import train\n",
    "# from train import *\n",
    "\n",
    "\n",
    "import ml_models\n",
    "from ml_models import *\n",
    "\n",
    "import dl_train\n",
    "from dl_train import *\n",
    "\n",
    "import tokenization\n",
    "from tokenization import *\n",
    "\n",
    "\n",
    "import behrt_train\n",
    "from behrt_train import *\n",
    "\n",
    "import feature_selection_icu\n",
    "from feature_selection_icu import *\n",
    "import fairness\n",
    "import callibrate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nutritional-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(day_intervals_cohort)\n",
    "import day_intervals_cohort\n",
    "from day_intervals_cohort import *\n",
    "\n",
    "importlib.reload(day_intervals_cohort_v2)\n",
    "import day_intervals_cohort_v2\n",
    "from day_intervals_cohort_v2 import *\n",
    "\n",
    "importlib.reload(data_generation_icu)\n",
    "import data_generation_icu\n",
    "importlib.reload(data_generation)\n",
    "import data_generation\n",
    "\n",
    "importlib.reload(feature_selection_hosp)\n",
    "import feature_selection_hosp\n",
    "from feature_selection_hosp import *\n",
    "\n",
    "importlib.reload(feature_selection_icu)\n",
    "import feature_selection_icu\n",
    "from feature_selection_icu import *\n",
    "\n",
    "importlib.reload(tokenization)\n",
    "import tokenization\n",
    "from tokenization import *\n",
    "\n",
    "importlib.reload(ml_models)\n",
    "import ml_models\n",
    "from ml_models import *\n",
    "\n",
    "importlib.reload(dl_train)\n",
    "import dl_train\n",
    "from dl_train import *\n",
    "\n",
    "importlib.reload(behrt_train)\n",
    "import behrt_train\n",
    "from behrt_train import *\n",
    "\n",
    "importlib.reload(fairness)\n",
    "import fairness\n",
    "\n",
    "importlib.reload(callibrate_output)\n",
    "import callibrate_output\n",
    "\n",
    "importlib.reload(evaluation)\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-demand",
   "metadata": {},
   "source": [
    "# Welcome to your MIMIC-IV Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-crown",
   "metadata": {},
   "source": [
    "This repository explains the steps to download and clean MIMIC-IV dataset for analysis.\n",
    "The repository is compatible with MIMIC-IV v1.0 and MIMIC-IV v2.0\n",
    "\n",
    "Please go to:\n",
    "- https://physionet.org/content/mimiciv/1.0/ for v1.0\n",
    "- https://physionet.org/content/mimiciv/2.0/ for v2.0\n",
    "\n",
    "Follow instructions to get access to MIMIC-IV dataset.\n",
    "\n",
    "Download the files using your terminal: \n",
    "- wget -r -N -c -np --user mehakg --ask-password https://physionet.org/files/mimiciv/1.0/ or\n",
    "- wget -r -N -c -np --user mehakg --ask-password https://physionet.org/files/mimiciv/2.0/\n",
    "        \n",
    "\n",
    "Save downloaded files in the parent directory of this github repo. \n",
    "\n",
    "The structure should look like below for v1.0-\n",
    "- mimiciv/1.0/core\n",
    "- mimiciv/1.0/hosp\n",
    "- mimiciv/1.0/icu\n",
    "\n",
    "The structure should look like below for v2.0-\n",
    "- mimiciv/2.0/hosp\n",
    "- mimiciv/2.0/icu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-tissue",
   "metadata": {},
   "source": [
    "## 1. DATA EXTRACTION\n",
    "Please run below cell to select option for cohort selection.\n",
    "The cohort will be svaed in **./data/cohort/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "structured-dimension",
   "metadata": {
    "tags": [
     "{",
     "\"tags\":",
     "[",
     "\"hide-input\"",
     "]",
     "}"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the approriate version of MIMIC-IV for which you have downloaded data ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afc37f8c3f848a687d9ac91578b8a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(index=1, options=('Version 1', 'Version 2'), value='Version 2')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select what prediction task you want to perform ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbba16c0fc2403ca2a97609c5c9dad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('Mortality', 'Length of Stay', 'Readmission', 'Phenotype'), value='Mortality')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Please select the approriate version of MIMIC-IV for which you have downloaded data ?\")\n",
    "version = widgets.RadioButtons(options=['Version 1','Version 2'],value='Version 2')\n",
    "display(version)\n",
    "\n",
    "print(\"Please select what prediction task you want to perform ?\")\n",
    "radio_input4 = widgets.RadioButtons(options=['Mortality','Length of Stay','Readmission','Phenotype'],value='Mortality')\n",
    "display(radio_input4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-syndicate",
   "metadata": {},
   "source": [
    "### Refining Cohort and Prediction Task Definition\n",
    "\n",
    "Based on your current selection following block will provide option to further refine prediction task and cohort associated with it:\n",
    "\n",
    "- First you will refine the prediction task choosing from following options -\n",
    "    - **length of Stay** - You can select from two predefined options or enter custom number of days to predict length os stay greater than number of days.\n",
    "\n",
    "    - **Readmission** - You can select from two predefined options or enter custom number of days to predict readmission after \"number of days\" after previous admission.\n",
    "\n",
    "    - **Phenotype Prediction** - You can select from four major chronic diseases to predict its future outcome\n",
    "\n",
    "        - Heart failure\n",
    "        - CAD (Coronary Artery Disease)\n",
    "        - CKD (Chronic Kidney Disease)\n",
    "        - COPD (Chronic obstructive pulmonary disease)\n",
    "\n",
    "- Second, you will choode whether to perfom above task using ICU or non-ICU admissions data\n",
    "\n",
    "- Third, you can refine the refine the cohort selection for any of the above choosen prediction tasks by including the admission samples admitted with particular chronic disease - \n",
    "    - Heart failure\n",
    "    - CAD (Coronary Artery Disease)\n",
    "    - CKD (Chronic Kidney Disease)\n",
    "    - COPD (Chronic obstructive pulmonary disease)\n",
    "    \n",
    "print(\"**Please run below cell to extract the cohort for selected options**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broke-spirituality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Data\n",
      "Please select below if you want to work with ICU or Non-ICU data ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f928455e9c43ff947fa9b59b7db83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('ICU', 'Non-ICU'), value='ICU')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select if you want to perform choosen prediction task for a specific disease.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730d37352a71400eaa41981e9098ce0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('No Disease Filter', 'Heart Failure', 'CKD', 'CAD', 'COPD'), value='No Disease Filter')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if radio_input4.value=='Length of Stay':\n",
    "    radio_input2 = widgets.RadioButtons(options=['Length of Stay ge 3','Length of Stay ge 7','Custom'],value='Length of Stay ge 3')\n",
    "    display(radio_input2)\n",
    "    text1=widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "    display(widgets.HBox([widgets.Label('Length of stay ge (in days)',layout={'width': '180px'}), text1]))\n",
    "elif radio_input4.value=='Readmission':\n",
    "    radio_input2 = widgets.RadioButtons(options=['30 Day Readmission','60 Day Readmission','90 Day Readmission','120 Day Readmission','Custom'],value='30 Day Readmission')\n",
    "    display(radio_input2)\n",
    "    text1=widgets.IntSlider(\n",
    "    value=30,\n",
    "    min=10,\n",
    "    max=150,\n",
    "    step=10,\n",
    "    disabled=False\n",
    "    )\n",
    "    display(widgets.HBox([widgets.Label('Readmission after (in days)',layout={'width': '180px'}), text1]))\n",
    "elif radio_input4.value=='Phenotype':\n",
    "    radio_input2 = widgets.RadioButtons(options=['Heart Failure in 30 days','CAD in 30 days','CKD in 30 days','COPD in 30 days'],value='Heart Failure in 30 days')\n",
    "    display(radio_input2)\n",
    "elif radio_input4.value=='Mortality':\n",
    "    radio_input2 = widgets.RadioButtons(options=['Mortality'],value='Mortality')\n",
    "    #display(radio_input2)\n",
    "\n",
    "print(\"Extract Data\")\n",
    "print(\"Please select below if you want to work with ICU or Non-ICU data ?\")\n",
    "radio_input1 = widgets.RadioButtons(options=['ICU', 'Non-ICU'],value='ICU')\n",
    "display(radio_input1)\n",
    "\n",
    "print(\"Please select if you want to perform choosen prediction task for a specific disease.\")\n",
    "radio_input3 = widgets.RadioButtons(options=['No Disease Filter','Heart Failure','CKD','CAD','COPD'],value='No Disease Filter')\n",
    "display(radio_input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "republican-freight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========MIMIC-IV v2.0============\n",
      "EXTRACTING FOR: | ICU | MORTALITY | 0 |\n",
      "[ MORTALITY LABELS FINISHED ]\n",
      "[ COHORT SUCCESSFULLY SAVED ]\n",
      "[ SUMMARY SUCCESSFULLY SAVED ]\n",
      "Mortality FOR ICU DATA\n",
      "# Admission Records: 140\n",
      "# Patients: 100\n",
      "# Positive cases: 10\n",
      "# Negative cases: 130\n"
     ]
    }
   ],
   "source": [
    "disease_label=\"\"\n",
    "time=0\n",
    "label=radio_input4.value\n",
    "\n",
    "if label=='Readmission':\n",
    "    if radio_input2.value=='Custom':\n",
    "        time=text1.value\n",
    "    else:\n",
    "        time=int(radio_input2.value.split()[0])\n",
    "elif label=='Length of Stay':\n",
    "    if radio_input2.value=='Custom':\n",
    "        time=text1.value\n",
    "    else:\n",
    "        time=int(radio_input2.value.split()[4])\n",
    "\n",
    "if label=='Phenotype':    \n",
    "    if radio_input2.value=='Heart Failure in 30 days':\n",
    "        label='Readmission'\n",
    "        time=30\n",
    "        disease_label='I50'\n",
    "    elif radio_input2.value=='CAD in 30 days':\n",
    "        label='Readmission'\n",
    "        time=30\n",
    "        disease_label='I25'\n",
    "    elif radio_input2.value=='CKD in 30 days':\n",
    "        label='Readmission'\n",
    "        time=30\n",
    "        disease_label='N18'\n",
    "    elif radio_input2.value=='COPD in 30 days':\n",
    "        label='Readmission'\n",
    "        time=30\n",
    "        disease_label='J44'\n",
    "    \n",
    "data_icu=radio_input1.value==\"ICU\"\n",
    "data_mort=label==\"Mortality\"\n",
    "data_admn=label=='Readmission'\n",
    "data_los=label=='Length of Stay'\n",
    "        \n",
    "\n",
    "if (radio_input3.value==\"Heart Failure\"):\n",
    "    icd_code='I50'\n",
    "elif (radio_input3.value==\"CKD\"):\n",
    "    icd_code='N18'\n",
    "elif (radio_input3.value==\"COPD\"):\n",
    "    icd_code='J44'\n",
    "elif (radio_input3.value==\"CAD\"):\n",
    "    icd_code='I25'\n",
    "else:\n",
    "    icd_code='No Disease Filter'\n",
    "\n",
    "if version.value=='Version 1':\n",
    "    version_path=\"mimiciv/1.0\"\n",
    "    cohort_output = day_intervals_cohort.extract_data(radio_input1.value,label,time,icd_code, root_dir,disease_label)\n",
    "elif version.value=='Version 2':\n",
    "    version_path=\"mimiciv/2.0\"\n",
    "    cohort_output = day_intervals_cohort_v2.extract_data(radio_input1.value,label,time,icd_code, root_dir,disease_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-stadium",
   "metadata": {},
   "source": [
    "## 2. FEATURE SELECTION\n",
    "Features available for ICU data -\n",
    "- Diagnosis (https://mimic.mit.edu/docs/iv/modules/hosp/diagnoses_icd/)\n",
    "- Procedures (https://mimic.mit.edu/docs/iv/modules/icu/procedureevents/)\n",
    "- Medications (https://mimic.mit.edu/docs/iv/modules/icu/inputevents/)\n",
    "- Output Events (https://mimic.mit.edu/docs/iv/modules/icu/outputevents/)\n",
    "- Chart Events (https://mimic.mit.edu/docs/iv/modules/icu/chartevents/)\n",
    "\n",
    "Features available for ICU data -\n",
    "- Diagnosis (https://mimic.mit.edu/docs/iv/modules/hosp/diagnoses_icd/)\n",
    "- Procedures (https://mimic.mit.edu/docs/iv/modules/hosp/procedures_icd/)\n",
    "- Medications (https://mimic.mit.edu/docs/iv/modules/hosp/prescriptions/)\n",
    "- Lab Events (https://mimic.mit.edu/docs/iv/modules/hosp/labevents/)\n",
    "\n",
    "All features will be saved in **./data/features/**\n",
    "\n",
    "**Please run below cell to select features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "raised-olympus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection\n",
      "Which Features you want to include for cohort?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4caed6b18f405d87c54c01df129d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Diagnosis')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3bfe8e468743f29a2cd2099dd89ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Output Events')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2e2d3dfb1243bea1d24f9ce8f42284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Chart Events(Labs and Vitals)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36230179cee74042b5906685a0c49c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Procedures')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403d517e6f9d4bdba368244fa6a27f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Medications')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Please run below cell to extract selected features**\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Selection\")\n",
    "if data_icu:\n",
    "    print(\"Which Features you want to include for cohort?\")\n",
    "    check_input1 = widgets.Checkbox(description='Diagnosis')\n",
    "    display(check_input1)\n",
    "    check_input2 = widgets.Checkbox(description='Output Events')\n",
    "    display(check_input2)\n",
    "    check_input3 = widgets.Checkbox(description='Chart Events(Labs and Vitals)')\n",
    "    display(check_input3)\n",
    "    check_input4 = widgets.Checkbox(description='Procedures')\n",
    "    display(check_input4)\n",
    "    check_input5 = widgets.Checkbox(description='Medications')\n",
    "    display(check_input5)\n",
    "else:\n",
    "    print(\"Which Features you want to include for cohort?\")\n",
    "    check_input1 = widgets.Checkbox(description='Diagnosis')\n",
    "    display(check_input1)\n",
    "    check_input2 = widgets.Checkbox(description='Labs')\n",
    "    display(check_input2)\n",
    "    check_input3 = widgets.Checkbox(description='Procedures')\n",
    "    display(check_input3)\n",
    "    check_input4 = widgets.Checkbox(description='Medications')\n",
    "    display(check_input4)\n",
    "print(\"**Please run below cell to extract selected features**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "native-covering",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_icu:\n",
    "    diag_flag=check_input1.value\n",
    "    out_flag=check_input2.value\n",
    "    chart_flag=check_input3.value\n",
    "    proc_flag=check_input4.value\n",
    "    med_flag=check_input5.value\n",
    "    feature_icu(cohort_output, version_path,diag_flag,out_flag,chart_flag,proc_flag,med_flag)\n",
    "else:\n",
    "    diag_flag=check_input1.value\n",
    "    lab_flag=check_input2.value\n",
    "    proc_flag=check_input3.value\n",
    "    med_flag=check_input4.value\n",
    "    feature_nonicu(cohort_output, version_path,diag_flag,lab_flag,proc_flag,med_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-upset",
   "metadata": {},
   "source": [
    "## 3. CLINICAL GROUPING\n",
    "Below you will have option to clinically group diagnosis and medications.\n",
    "Grouping medical codes will reduce dimensional space of features.\n",
    "\n",
    "Default options selected below will group medical codes to reduce feature dimension space.\n",
    "\n",
    "**Please run below cell to select preprocessing for diferent features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "partial-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Please run below cell to perform feature preprocessing**\n"
     ]
    }
   ],
   "source": [
    "if data_icu:\n",
    "    if diag_flag:\n",
    "        print(\"Do you want to group ICD 10 DIAG codes ?\")\n",
    "        radio_input4 = widgets.RadioButtons(options=['Keep both ICD-9 and ICD-10 codes','Convert ICD-9 to ICD-10 codes','Convert ICD-9 to ICD-10 and group ICD-10 codes'],value='Convert ICD-9 to ICD-10 and group ICD-10 codes',layout={'width': '100%'})\n",
    "        display(radio_input4)   \n",
    "    \n",
    "else:\n",
    "    if diag_flag:\n",
    "        print(\"Do you want to group ICD 10 DIAG codes ?\")\n",
    "        radio_input4 = widgets.RadioButtons(options=['Keep both ICD-9 and ICD-10 codes','Convert ICD-9 to ICD-10 codes','Convert ICD-9 to ICD-10 and group ICD-10 codes'],value='Convert ICD-9 to ICD-10 and group ICD-10 codes',layout={'width': '100%'})\n",
    "        display(radio_input4)     \n",
    "    if med_flag:\n",
    "        print(\"Do you want to group Medication codes to use Non propietary names?\")\n",
    "        radio_input5 = widgets.RadioButtons(options=['Yes','No'],value='Yes',layout={'width': '100%'})\n",
    "        display(radio_input5)\n",
    "    if proc_flag:\n",
    "        print(\"Which ICD codes for Procedures you want to keep in data?\")\n",
    "        radio_input6 = widgets.RadioButtons(options=['ICD-9 and ICD-10','ICD-10'],value='ICD-10',layout={'width': '100%'})\n",
    "        display(radio_input6)\n",
    "print(\"**Please run below cell to perform feature preprocessing**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "descending-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_diag=False\n",
    "group_med=False\n",
    "group_proc=False\n",
    "if data_icu:\n",
    "    if diag_flag:\n",
    "        group_diag=radio_input4.value\n",
    "    preprocess_features_icu(cohort_output, diag_flag, group_diag,False,False,False,0,0)\n",
    "else:\n",
    "    if diag_flag:\n",
    "        group_diag=radio_input4.value\n",
    "    if med_flag:\n",
    "        group_med=radio_input5.value\n",
    "    if proc_flag:\n",
    "        group_proc=radio_input6.value\n",
    "    preprocess_features_hosp(cohort_output, diag_flag,proc_flag,med_flag,False,group_diag,group_med,group_proc,False,False,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-captain",
   "metadata": {},
   "source": [
    "### 4. SUMMARY OF FEATURES\n",
    "\n",
    "This step will generate summary of all features extracted so far.<br>\n",
    "It will save summary files in **./data/summary/**<br>\n",
    "- These files provide summary about **mean frequency** of medical codes per admission.<br>\n",
    "- It also provides **total occurrence count** of each medical code.<br>\n",
    "- For labs and chart events it will also provide <br>**missing %** which tells how many rows for a certain medical code has missing value.\n",
    "\n",
    "Please use this information to further refine your cohort by selecting <br>which medical codes in each feature you want to keep and <br>which codes you would like to remove for downstream analysis tasks.\n",
    "\n",
    "**Please run below cell to generate summary files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thick-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GENERATING FEATURE SUMMARY]\n",
      "[SUCCESSFULLY SAVED FEATURE SUMMARY]\n"
     ]
    }
   ],
   "source": [
    "if data_icu:\n",
    "    generate_summary_icu(diag_flag,proc_flag,med_flag,out_flag,chart_flag)\n",
    "else:\n",
    "    generate_summary_hosp(diag_flag,proc_flag,med_flag,lab_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-architecture",
   "metadata": {},
   "source": [
    "## 5. Feature Selection\n",
    "\n",
    "based on the files generated in previous step and other infromation gathered by you,<br>\n",
    "Please select which medical codes you want to include in this study.\n",
    "\n",
    "Please run below cell to to select options for which features you want to perform feature selection.\n",
    "\n",
    "- Select **Yes** if you want to select a subset of medical codes for that feature and<br> **edit** the corresponding feature file for it.\n",
    "- Select **No** if you want to keep all the codes in a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immediate-seafood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Please run below cell to perform feature selection**\n"
     ]
    }
   ],
   "source": [
    "if data_icu:\n",
    "    if diag_flag:\n",
    "        print(\"Do you want to do Feature Selection for Diagnosis \\n (If yes, please edit list of codes in ./data/summary/diag_features.csv)\")\n",
    "        radio_input4 = widgets.RadioButtons(options=['Yes','No'],value='No')\n",
    "        display(radio_input4)       \n",
    "    if med_flag:\n",
    "        print(\"Do you want to do Feature Selection for Medication \\n (If yes, please edit list of codes in ./data/summary/med_features.csv)\")\n",
    "        radio_input5 = widgets.RadioButtons(options=['Yes','No'],value='No')\n",
    "        display(radio_input5)   \n",
    "    if proc_flag:\n",
    "        print(\"Do you want to do Feature Selection for Procedures \\n (If yes, please edit list of codes in ./data/summary/proc_features.csv)\")\n",
    "        radio_input6 = widgets.RadioButtons(options=['Yes','No'],value='No')\n",
    "        display(radio_input6)   \n",
    "    if out_flag:\n",
    "        print(\"Do you want to do Feature Selection for Output event \\n (If yes, please edit list of codes in ./data/summary/out_features.csv)\")\n",
    "        radio_input7 = widgets.RadioButtons(options=['Yes','No'],value='No')\n",
    "        display(radio_input7)  \n",
    "    if chart_flag:\n",
    "        print(\"Do you want to do Feature Selection for Chart events \\n (If yes, please edit list of codes in ./data/summary/chart_features.csv)\")\n",
    "        radio_input8 = widgets.RadioButtons(options=['Yes','No'],value='No')\n",
    "        display(radio_input8)  \n",
    "else:\n",
    "    if diag_flag:\n",
    "        print(\"Do you want to do Feature Selection for Diagnosis \\n (If yes, please edit list of codes in ./data/summary/diag_features.csv)\")\n",
    "        radio_input4 = widgets.RadioButtons(options=['Yes','No'],value='No')\n",
    "        display(radio_input4)         \n",
    "    if med_flag:\n",
    "        print(\"Do you want to do Feature Selection for Medication \\n (If yes, please edit list of codes in ./data/summary/med_features.csv)\")\n",
    "        radio_input5 = widgets.RadioButtons(options=['Yes','No'],value='No')\n",
    "        display(radio_input5)   \n",
    "    if proc_flag:\n",
    "        print(\"Do you want to do Feature Selection for Procedures \\n (If yes, please edit list of codes in ./data/summary/proc_features.csv)\")\n",
    "        radio_input6 = widgets.RadioButtons(options=['Yes','No'],value='No')\n",
    "        display(radio_input6)   \n",
    "    if lab_flag:\n",
    "        print(\"Do you want to do Feature Selection for Labs \\n (If yes, please edit list of codes in ./data/summary/lab_features.csv)\")\n",
    "        radio_input7 = widgets.RadioButtons(options=['Yes','No'],value='No')\n",
    "        display(radio_input7)   \n",
    "print(\"**Please run below cell to perform feature selection**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "perceived-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_diag=False\n",
    "select_med=False\n",
    "select_proc=False\n",
    "select_lab=False\n",
    "select_out=False\n",
    "select_chart=False\n",
    "\n",
    "if data_icu:\n",
    "    if diag_flag:\n",
    "        select_diag=radio_input4.value == 'Yes'\n",
    "    if med_flag:\n",
    "        select_med=radio_input5.value == 'Yes'\n",
    "    if proc_flag:\n",
    "        select_proc=radio_input6.value == 'Yes'\n",
    "    if out_flag:\n",
    "        select_out=radio_input7.value == 'Yes'\n",
    "    if chart_flag:\n",
    "        select_chart=radio_input8.value == 'Yes'\n",
    "    features_selection_icu(cohort_output, diag_flag,proc_flag,med_flag,out_flag, chart_flag,select_diag,select_med,select_proc,select_out,select_chart)\n",
    "else:\n",
    "    if diag_flag:\n",
    "        select_diag=radio_input4.value == 'Yes'\n",
    "    if med_flag:\n",
    "        select_med=radio_input5.value == 'Yes'\n",
    "    if proc_flag:\n",
    "        select_proc=radio_input6.value == 'Yes'\n",
    "    if lab_flag:\n",
    "        select_lab=radio_input7.value == 'Yes'\n",
    "    features_selection_hosp(cohort_output, diag_flag,proc_flag,med_flag,lab_flag,select_diag,select_med,select_proc,select_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-director",
   "metadata": {},
   "source": [
    "## 6. CLEANING OF FEATURES\n",
    "Below you will have option to to clean lab and chart events by performing outlier removal and unit conversion.\n",
    "\n",
    "Outlier removal is performed to remove values higher than selected **right threshold** percentile and lower than selected **left threshold** percentile among all values for each itemid. \n",
    "\n",
    "**Please run below cell to select preprocessing for diferent features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "moderate-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Please run below cell to perform feature preprocessing**\n"
     ]
    }
   ],
   "source": [
    "if data_icu:\n",
    "    if chart_flag:\n",
    "        print(\"Outlier removal in values of chart events ?\")\n",
    "        layout = widgets.Layout(width='100%', height='40px') #set width and height\n",
    "\n",
    "        radio_input5 = widgets.RadioButtons(options=['No outlier detection','Impute Outlier (default:98)','Remove outliers (default:98)'],value='No outlier detection',layout=layout)\n",
    "        display(radio_input5)\n",
    "        outlier=widgets.IntSlider(\n",
    "        value=98,\n",
    "        min=90,\n",
    "        max=99,\n",
    "        step=1,\n",
    "        disabled=False,layout={'width': '100%'}\n",
    "        )\n",
    "        left_outlier=widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        disabled=False,layout={'width': '100%'}\n",
    "        )\n",
    "        #display(oulier)\n",
    "        display(widgets.HBox([widgets.Label('Right Outlier Threshold',layout={'width': '150px'}), outlier]))\n",
    "        display(widgets.HBox([widgets.Label('Left Outlier Threshold',layout={'width': '150px'}), left_outlier]))\n",
    "    \n",
    "else:      \n",
    "    if lab_flag:\n",
    "        print(\"Outlier removal in values of lab events ?\")\n",
    "        layout = widgets.Layout(width='100%', height='40px') #set width and height\n",
    "\n",
    "        radio_input7 = widgets.RadioButtons(options=['No outlier detection','Impute Outlier (default:98)','Remove outliers (default:98)'],value='No outlier detection',layout=layout)\n",
    "        display(radio_input7)\n",
    "        outlier=widgets.IntSlider(\n",
    "        value=98,\n",
    "        min=90,\n",
    "        max=99,\n",
    "        step=1,\n",
    "        disabled=False,layout={'width': '100%'}\n",
    "        )\n",
    "        left_outlier=widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        disabled=False,layout={'width': '100%'}\n",
    "        )\n",
    "        #display(oulier)\n",
    "        display(widgets.HBox([widgets.Label('Right Outlier Threshold',layout={'width': '150px'}), outlier]))\n",
    "        display(widgets.HBox([widgets.Label('Left Outlier Threshold',layout={'width': '150px'}), left_outlier]))\n",
    "print(\"**Please run below cell to perform feature preprocessing**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "impossible-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=0\n",
    "# added this - it could break things, but logic is broken\n",
    "clean_chart=False\n",
    "chart_flag=False\n",
    "impute_outlier_chart=False\n",
    "left_thresh = 0\n",
    "\n",
    "if data_icu:\n",
    "    if chart_flag:\n",
    "        clean_chart=radio_input5.value!='No outlier detection'\n",
    "        impute_outlier_chart=radio_input5.value=='Impute Outlier (default:98)'\n",
    "        thresh=outlier.value\n",
    "        left_thresh=left_outlier.value\n",
    "    preprocess_features_icu(cohort_output, False, False,chart_flag,clean_chart,impute_outlier_chart,thresh,left_thresh)\n",
    "else:\n",
    "    if lab_flag:\n",
    "        clean_lab=radio_input7.value!='No outlier detection'\n",
    "        impute_outlier=radio_input7.value=='Impute Outlier (default:98)'\n",
    "        thresh=outlier.value\n",
    "        left_thresh=left_outlier.value\n",
    "    preprocess_features_hosp(cohort_output, False,False,False,lab_flag,False,False,False,clean_lab,impute_outlier,thresh,left_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-academy",
   "metadata": {},
   "source": [
    "## 7. Time-Series Representation\n",
    "In this section, please choose how you want to process and represent time-series data.\n",
    "\n",
    "- First option is to select the length of time-series data you want to include for this study. (Default is 72 hours)\n",
    "\n",
    "- Second option is to select bucket size which tells in what size time windows you want to divide your time-series.<br>\n",
    "For example, if you select **2** bucket size, it wil aggregate data for every 2 hours and <br>a time-series of length 24 hours will be represented as time-series with 12 time-windows <br>where data for every 2 hours is agggregated from original raw time-series.\n",
    "\n",
    "During this step, we will also save the time-series data in data dictionaries in the format that can be directly used for following deep learning analysis.\n",
    "\n",
    "### Imputation\n",
    "You can also choose if you want to impute lab/chart values. The imputation will be done by froward fill and mean or median imputation.<br>\n",
    "Values will be forward fill first and if no value exists for that admission we will use mean or median value for the patient.\n",
    "\n",
    "The data dictionaries will be saved in **./data/dict/**\n",
    "\n",
    "Please refer the readme to know the structure of data dictionaries.\n",
    "\n",
    "**Please run below cell to select time-series representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "mechanical-three",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Time-series Data Represenation=======\n",
      "Length of data to be included for time-series prediction ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335872362ae84d1889c261165ed26882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('First 72 hours', 'First 48 hours', 'First 24 hours', 'Custom'), value='First 72 hours')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab6b8593a074b5887bd7c12175fba5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Fisrt (in hours):', layout=Layout(width='150px')), IntSlider(value=72, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What time bucket size you want to choose ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc40da09e1044329adaca9cb498a6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('1 hour', '2 hour', '3 hour', '4 hour', '5 hour', 'Custom'), value='1 hour')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d2efd82fc649d7b1cf7f7b86fdfc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Bucket Size (in hours):', layout=Layout(width='150px')), IntSlider(value=1, max=6,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to forward fill and mean or median impute lab/chart values to form continuous data signal?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5684aabc47164bffb60a836bbe210d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('No Imputation', 'forward fill and mean', 'forward fill and median'), value='No Imputati…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you have choosen mortality prediction task, then what prediction window length you want to keep?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eafc61de4e4f319e6c45107f7ccb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('2 hours', '4 hours', '6 hours', '8 hours', 'Custom'), value='2 hours')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cf328dabfb45a08a324a0835158393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Prediction window (in hours)', layout=Layout(width='180px')), IntSlider(value=2, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Please run below cell to perform time-series represenation and save in data dictionaries**\n"
     ]
    }
   ],
   "source": [
    "print(\"=======Time-series Data Represenation=======\")\n",
    "\n",
    "print(\"Length of data to be included for time-series prediction ?\")\n",
    "if(data_mort):\n",
    "    radio_input8 = widgets.RadioButtons(options=['First 72 hours','First 48 hours','First 24 hours','Custom'],value='First 72 hours')\n",
    "    display(radio_input8)\n",
    "    text2=widgets.IntSlider(\n",
    "    value=72,\n",
    "    min=24,\n",
    "    max=72,\n",
    "    step=1,\n",
    "    description='Fisrt',\n",
    "    disabled=False\n",
    "    )\n",
    "    display(widgets.HBox([widgets.Label('Fisrt (in hours):',layout={'width': '150px'}), text2]))\n",
    "elif(data_admn):\n",
    "    radio_input8 = widgets.RadioButtons(options=['Last 72 hours','Last 48 hours','Last 24 hours','Custom'],value='Last 72 hours')\n",
    "    display(radio_input8)\n",
    "    text2=widgets.IntSlider(\n",
    "    value=72,\n",
    "    min=24,\n",
    "    max=72,\n",
    "    step=1,\n",
    "    description='Last',\n",
    "    disabled=False\n",
    "    )\n",
    "    display(widgets.HBox([widgets.Label('Last (in hours):',layout={'width': '150px'}), text2]))\n",
    "elif(data_los):\n",
    "    radio_input8 = widgets.RadioButtons(options=['First 12 hours','First 24 hours','Custom'],value='First 24 hours')\n",
    "    display(radio_input8)\n",
    "    text2=widgets.IntSlider(\n",
    "    value=72,\n",
    "    min=12,\n",
    "    max=72,\n",
    "    step=1,\n",
    "    description='First',\n",
    "    disabled=False\n",
    "    )\n",
    "    display(widgets.HBox([widgets.Label('Fisrt (in hours):',layout={'width': '150px'}), text2]))\n",
    "    \n",
    "    \n",
    "print(\"What time bucket size you want to choose ?\")\n",
    "radio_input7 = widgets.RadioButtons(options=['1 hour','2 hour','3 hour','4 hour','5 hour','Custom'],value='1 hour')\n",
    "display(radio_input7)\n",
    "text1=widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=6,\n",
    "    step=1,\n",
    "    disabled=False\n",
    "    )\n",
    "#display(text1)\n",
    "display(widgets.HBox([widgets.Label('Bucket Size (in hours):',layout={'width': '150px'}), text1]))\n",
    "print(\"Do you want to forward fill and mean or median impute lab/chart values to form continuous data signal?\")\n",
    "radio_impute = widgets.RadioButtons(options=['No Imputation', 'forward fill and mean','forward fill and median'],value='No Imputation')\n",
    "display(radio_impute)   \n",
    "\n",
    "radio_input6 = widgets.RadioButtons(options=['0 hours','2 hours','4 hours','6 hours'],value='0 hours')\n",
    "if(data_mort):\n",
    "    print(\"If you have choosen mortality prediction task, then what prediction window length you want to keep?\")\n",
    "    radio_input6 = widgets.RadioButtons(options=['2 hours','4 hours','6 hours','8 hours','Custom'],value='2 hours')\n",
    "    display(radio_input6)\n",
    "    text3=widgets.IntSlider(\n",
    "    value=2,\n",
    "    min=2,\n",
    "    max=8,\n",
    "    step=1,\n",
    "    disabled=False\n",
    "    )\n",
    "    display(widgets.HBox([widgets.Label('Prediction window (in hours)',layout={'width': '180px'}), text3]))\n",
    "print(\"**Please run below cell to perform time-series represenation and save in data dictionaries**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "indie-appendix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ READ COHORT ]\n",
      "[ READ ALL FEATURES ]\n",
      "include_time 72\n",
      "[ PROCESSED TIME SERIES TO EQUAL LENGTH  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 610080.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket 1\n",
      "[ PROCESSED TIME SERIES TO EQUAL TIME INTERVAL ]\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 465.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESSFULLY SAVED DATA DICTIONARIES ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if (radio_input6.value=='Custom'):\n",
    "    predW=int(text3.value)\n",
    "else:\n",
    "    predW=int(radio_input6.value[0].strip())\n",
    "if (radio_input7.value=='Custom'):\n",
    "    bucket=int(text1.value)\n",
    "else:\n",
    "    bucket=int(radio_input7.value[0].strip())\n",
    "if (radio_input8.value=='Custom'):\n",
    "    include=int(text2.value)\n",
    "else:\n",
    "    include=int(radio_input8.value.split()[1])\n",
    "if (radio_impute.value=='forward fill and mean'):\n",
    "    impute='Mean'\n",
    "elif (radio_impute.value=='forward fill and median'):\n",
    "    impute='Median'\n",
    "else:\n",
    "    impute=False\n",
    "\n",
    "if data_icu:\n",
    "    gen=data_generation_icu.Generator(cohort_output,data_mort,data_admn,data_los,diag_flag,proc_flag,out_flag,chart_flag,med_flag,impute,include,bucket,predW)\n",
    "    #gen=data_generation_icu.Generator(cohort_output,data_mort,diag_flag,False,False,chart_flag,False,impute,include,bucket,predW)\n",
    "    #if chart_flag:\n",
    "    #    gen=data_generation_icu.Generator(cohort_output,data_mort,False,False,False,chart_flag,False,impute,include,bucket,predW)\n",
    "else:\n",
    "    gen=data_generation.Generator(cohort_output,data_mort,data_admn,data_los,diag_flag,lab_flag,proc_flag,med_flag,impute,include,bucket,predW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-reset",
   "metadata": {},
   "source": [
    "## 8. Machine Learning Models\n",
    "\n",
    "Below we provide options to select -\n",
    "- Type of machine learning model\n",
    "- Wheteher to concatenate or aggregate time-series features.\n",
    "    For example, if the EHR data has collected value for Blood Pressure for one year over 4 time windows of 3 months each then,\n",
    "    - **Conactenate** will concatenate all four values resulting in 4 different features for blood pressure,\n",
    "    - **Aggregate** will aggreagte(mean) over four tiem windows resulting in one feature for blood pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "consolidated-former",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Machine :earning Models=======\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f577e83fca64ae9a53bd29cda9d0ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(index=2, options=('Logistic Regression', 'Random Forest', 'Gradient Bossting', 'Xgboost'), value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you wnat to conactenate the time-series feature\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fa0cbda47849b2a300dfc377a43f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('Conactenate', 'Aggregate'), value='Conactenate')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select below option for cross-validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c274077476442b974721967efd3a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(index=1, options=('No CV', '5-fold CV', '10-fold CV'), value='5-fold CV')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to do oversampling for minority calss ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2bf9a39518499eb80ef4d3a78c1230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('True', 'False'), value='True')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=======Machine :earning Models=======\")\n",
    "radio_input5 = widgets.RadioButtons(options=['Logistic Regression','Random Forest','Gradient Bossting','Xgboost'],value='Gradient Bossting')\n",
    "display(radio_input5)\n",
    "print(\"Do you wnat to conactenate the time-series feature\")\n",
    "radio_input6 = widgets.RadioButtons(options=['Conactenate','Aggregate'],value='Conactenate')\n",
    "display(radio_input6)\n",
    "print(\"Please select below option for cross-validation\")\n",
    "radio_input7 = widgets.RadioButtons(options=['No CV','5-fold CV','10-fold CV'],value='5-fold CV')\n",
    "display(radio_input7)\n",
    "print(\"Do you want to do oversampling for minority calss ?\")\n",
    "radio_input8 = widgets.RadioButtons(options=['True','False'],value='True')\n",
    "display(radio_input8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "promising-miller",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples 54\n",
      "Positive Samples 9\n",
      "=============OVERSAMPLING===============\n",
      "Total Samples 90\n",
      "Positive Samples 45\n",
      "=================== 0 FOLD=====================\n",
      "train_hids 72\n",
      "X_df (72, 270)\n",
      "y_df (72,)\n",
      "(72, 270)\n",
      "(72,)\n",
      "test_hids 18\n",
      "X_df (18, 121)\n",
      "y_df (18,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'BLACK/CAPE VERDEAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/utils/_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/utils/_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BLACK/CAPE VERDEAN'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m radio_input7\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10-fold CV\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m ml\u001b[38;5;241m=\u001b[39m\u001b[43mml_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mML_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_icu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mradio_input5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconcat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradio_input6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mConactenate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moversampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradio_input8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# stat df has no COND?\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/MIMIC-IV-Data-Pipeline/model/ml_models.py:39\u001b[0m, in \u001b[0;36mML_models.__init__\u001b[0;34m(self, data_icu, k_fold, model_type, concat, oversampling)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moversampling \u001b[38;5;241m=\u001b[39m oversampling\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mLoss(\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mml_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/MIMIC-IV-Data-Pipeline/model/ml_models.py:130\u001b[0m, in \u001b[0;36mML_models.ml_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    129\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m gen_encoder\u001b[38;5;241m.\u001b[39mtransform(X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 130\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124methnicity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43meth_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43methnicity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minsurance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ins_encoder\u001b[38;5;241m.\u001b[39mtransform(X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minsurance\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# X_test['Age']=age_encoder.transform(X_test['Age'])\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/utils/_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'BLACK/CAPE VERDEAN'"
     ]
    }
   ],
   "source": [
    "if radio_input7.value=='No CV':\n",
    "    cv=0\n",
    "elif radio_input7.value=='5-fold CV':\n",
    "    cv=int(5)\n",
    "elif radio_input7.value=='10-fold CV':\n",
    "    cv=int(10)\n",
    "ml=ml_models.ML_models(data_icu,cv,radio_input5.value,concat=radio_input6.value=='Conactenate',oversampling=radio_input8.value=='True')\n",
    "\n",
    "# stat df has no COND?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-chancellor",
   "metadata": {},
   "source": [
    "## 9. Deep Learning Models\n",
    "- Time-series LSTM and Time-series CNN which will only use time-series events like medications, charts, labs, output events to train model.\n",
    "\n",
    "- Hybrid LSTM and Hybrid CNN will use static data - diagnosis, demographic data aong with other time-series data to train model.\n",
    "\n",
    "- LSTM with Attention model will use attention layer to rank the important features and learn to predict output. It will use both static and time-series data.\n",
    "\n",
    "**Go to ./model/parameter.py and define all variables needed for model building and training**\n",
    "\n",
    "**Please run below cell to select which model to use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "operational-pride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7b6e759e5848cdb398c83d078fdc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('Time-series LSTM', 'Time-series CNN', 'Hybrid LSTM', 'Hybrid CNN'), value='Time-series …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select below option for cross-validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad54b2ea1244ae6ae3ab4731d8378a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(index=1, options=('No CV', '5-fold CV', '10-fold CV'), value='5-fold CV')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to do oversampling for minority calss ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e43e720d60f46e499ad6c331e079edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('True', 'False'), value='True')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "radio_input6=widgets.RadioButtons(options=['Time-series LSTM','Time-series CNN','Hybrid LSTM','Hybrid CNN'],value='Time-series LSTM')\n",
    "display(radio_input6)\n",
    "print(\"Please select below option for cross-validation\")\n",
    "radio_input7 = widgets.RadioButtons(options=['No CV','5-fold CV','10-fold CV'],value='5-fold CV')\n",
    "display(radio_input7)\n",
    "print(\"Do you want to do oversampling for minority calss ?\")\n",
    "radio_input8 = widgets.RadioButtons(options=['True','False'],value='True')\n",
    "display(radio_input8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "golden-stewart",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============MODEL TRAINING===============\n",
      "Total Samples 54\n",
      "Positive Samples 9\n",
      "=============OVERSAMPLING===============\n",
      "Total Samples 90\n",
      "Positive Samples 45\n",
      "[ MODEL CREATED ]\n",
      "LSTMBase(\n",
      "  (ethEmbed): Embedding(8, 152, padding_idx=0)\n",
      "  (genderEmbed): Embedding(3, 152, padding_idx=0)\n",
      "  (ageEmbed): Embedding(37, 152, padding_idx=0)\n",
      "  (insEmbed): Embedding(4, 152, padding_idx=0)\n",
      "  (embedfc): Linear(in_features=608, out_features=152, bias=True)\n",
      "  (rnn): LSTM(152, 256, num_layers=2, batch_first=True)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "=================== 0 FOLD=====================\n",
      "======= EPOCH 0.0 ========\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true takes value in {} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_icu:\n\u001b[0;32m----> 9\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mdl_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDL_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_icu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdiag_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43mproc_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchart_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmed_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mradio_input6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43moversampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradio_input8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattn_icu_read\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39mdl_train\u001b[38;5;241m.\u001b[39mDL_models(data_icu,diag_flag,proc_flag,\u001b[38;5;28;01mFalse\u001b[39;00m,\u001b[38;5;28;01mFalse\u001b[39;00m,med_flag,lab_flag,radio_input6\u001b[38;5;241m.\u001b[39mvalue,cv,oversampling\u001b[38;5;241m=\u001b[39mradio_input8\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m,model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattn_icu_read\u001b[39m\u001b[38;5;124m'\u001b[39m,train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/MIMIC-IV-Data-Pipeline/model/dl_train.py:83\u001b[0m, in \u001b[0;36mDL_models.__init__\u001b[0;34m(self, data_icu, diag_flag, proc_flag, out_flag, chart_flag, med_flag, lab_flag, model_type, k_fold, oversampling, model_name, train)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===============MODEL TRAINING===============\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdl_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_path)\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/MIMIC-IV-Data-Pipeline/model/dl_train.py:180\u001b[0m, in \u001b[0;36mDL_models.dl_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m     train_logits\u001b[38;5;241m.\u001b[39mextend(logits\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m#print(train_prob)\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m#print(train_truth)\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_prob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_truth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_logits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m val_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_val(val_hids)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m#print(\"Updating Model\")\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m#T.save(self.net,self.save_path)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/MIMIC-IV-Data-Pipeline/model/evaluation.py:98\u001b[0m, in \u001b[0;36mLoss.forward\u001b[0;34m(self, prob, labels, logits, train, standalone)\u001b[0m\n\u001b[1;32m     94\u001b[0m         prob \u001b[38;5;241m=\u001b[39m prob\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauroc):\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#             print(labels)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#             print(prob)\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m             fpr, tpr, threshholds \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m             auc \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mauc(fpr, tpr)\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maurocPlot):\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1145\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1044\u001b[0m     {\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m ):\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1145\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:834\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    831\u001b[0m     y_score \u001b[38;5;241m=\u001b[39m y_score[nonzero_weight_mask]\n\u001b[1;32m    832\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight[nonzero_weight_mask]\n\u001b[0;32m--> 834\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[43m_check_pos_label_consistency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# make y_true a boolean vector\u001b[39;00m\n\u001b[1;32m    837\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true \u001b[38;5;241m==\u001b[39m pos_label\n",
      "File \u001b[0;32m~/Documents/ehrapy_workspace/mimic-iv-pipeline-venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2503\u001b[0m, in \u001b[0;36m_check_pos_label_consistency\u001b[0;34m(pos_label, y_true)\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m classes\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUS\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m   2496\u001b[0m         np\u001b[38;5;241m.\u001b[39marray_equal(classes, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   2497\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(classes, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(classes, [\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   2501\u001b[0m     ):\n\u001b[1;32m   2502\u001b[0m         classes_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mrepr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m classes\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[0;32m-> 2503\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2504\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true takes value in \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclasses_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m and pos_label is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2505\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified: either make y_true take value in \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0, 1} or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2506\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m-1, 1} or pass pos_label explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2507\u001b[0m         )\n\u001b[1;32m   2508\u001b[0m     pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pos_label\n",
      "\u001b[0;31mValueError\u001b[0m: y_true takes value in {} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly."
     ]
    }
   ],
   "source": [
    "if radio_input7.value=='No CV':\n",
    "    cv=0\n",
    "elif radio_input7.value=='5-fold CV':\n",
    "    cv=int(5)\n",
    "elif radio_input7.value=='10-fold CV':\n",
    "    cv=int(10)\n",
    "    \n",
    "if data_icu:\n",
    "    model=dl_train.DL_models(data_icu,diag_flag,proc_flag,out_flag,chart_flag,med_flag,False,radio_input6.value,cv,oversampling=radio_input8.value=='True',model_name='attn_icu_read',train=True)\n",
    "else:\n",
    "    model=dl_train.DL_models(data_icu,diag_flag,proc_flag,False,False,med_flag,lab_flag,radio_input6.value,cv,oversampling=radio_input8.value=='True',model_name='attn_icu_read',train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-factor",
   "metadata": {},
   "source": [
    "## 10. Running BEHRT\n",
    "Below we integrate the implementation of BEHRT in our pipeline.\n",
    "We perform pre-procesing needed to run BEHRT model. https://github.com/deepmedicine/BEHRT\n",
    "\n",
    "Few things to note before running BEHRT -\n",
    "- The numerical values are binned into quantiles.\n",
    "- BEHRT has recommended maximum number of events per sample to be 512. \n",
    "    So feature selection is important so that number of events per sample does not exceed 512.\n",
    "- The model is quite computationally heavy so it requires a GPU.\n",
    "\n",
    "The output files for BEHRT will be saved in ./data/behrt/ folder\n",
    "\n",
    "**Please run below cell to to pre-process and run BEHRT on the selected cohort**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_icu:\n",
    "    token=tokenization.BEHRT_models(data_icu,diag_flag,proc_flag,out_flag,chart_flag,med_flag,False)\n",
    "    tokenized_src, tokenized_age, tokenized_gender, tokenized_ethni, tokenized_ins, tokenized_labels=token.tokenize()\n",
    "else:\n",
    "    token=tokenization.BEHRT_models(data_icu,diag_flag,proc_flag,False,False,med_flag,lab_flag)\n",
    "    tokenized_src, tokenized_age, tokenized_gender, tokenized_ethni, tokenized_ins, tokenized_labels=token.tokenize()\n",
    "    \n",
    "behrt_train.train_behrt(tokenized_src, tokenized_age, tokenized_gender, tokenized_ethni, tokenized_ins, tokenized_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-objective",
   "metadata": {},
   "source": [
    "### EVALUATION AS STANDALONE MODULE\n",
    "Below cell shows an exaple of how evaluation module can be used as a standalone module.\n",
    "\n",
    "evaluation.Loss class can be instantiated and model output and ground truth can be passed to it to obtain results.\n",
    "\n",
    "In the example below we captured model output and ground truth in a file and used that file to read the data.\n",
    "\n",
    "In function definition ***loss(prob,truth,logits,False)***\n",
    "\n",
    "prob -> List of Output predicted probabilities of case being positive\n",
    "\n",
    "truth -> List of ground truth labels\n",
    "\n",
    "logits -> List of logits obtained from last fully connected layer before applying softmax.sigmoid function in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device='cuda:0'\n",
    "#device='cpu'\n",
    "loss=evaluation.Loss(device,acc=True,ppv=True,sensi=True,tnr=True,npv=True,auroc=True,aurocPlot=True,auprc=True,auprcPlot=True,callb=True,callbPlot=True)\n",
    "with open(\"./data/output/outputDict\", 'rb') as fp:\n",
    "    outputDict=pickle.load(fp)\n",
    "prob=list(outputDict['Prob'])\n",
    "truth=list(outputDict['Labels'])\n",
    "logits=list(outputDict['Logits'])\n",
    "#print(torch.tensor(prob))\n",
    "print(\"======= TESTING ========\")\n",
    "loss(prob,truth,logits,train=False,standalone=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-works",
   "metadata": {},
   "source": [
    "### 11. FAIRNESS EVALUATION\n",
    "In train and testing step we save output files in **./data/output/** folder.\n",
    "\n",
    "This file conatins list of demographic variables included in training and testing of the model.\n",
    "\n",
    "It also contains the ground truth labels and predicted probability for each sample.\n",
    "\n",
    "We use the above saved data to perform fairness evaluation of the results obtained from model testing.\n",
    "\n",
    "This module can be used as stand-alone module also.\n",
    "\n",
    "Please create a file that contains predicted probabilites form the last sigmoid layer in column named **Prob** and\n",
    "ground truth labels for each sample in column named **Labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness.fairness_evaluation(inputFile='outputDict',outputFile='fairnessReport')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-distinction",
   "metadata": {},
   "source": [
    "### 12. MODEL CALLIBRATION\n",
    "\n",
    "Please run below cell if you want to callibrate predicted probabilites of the model on test data.\n",
    "It will use the output saved during the testing of the model.\n",
    "\n",
    "The file is saved in **./data/output/**.\n",
    "\n",
    "This module can be used as stand-alone module also.\n",
    "\n",
    "Please create a file that contain predicted logits form the last fully connected layer in column named **Logits** and <br>ground truth labels for each sample in a column named **Labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "callibrate_output.callibrate(inputFile='outputDict',outputFile='callibratedResults')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-canyon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "mimic-iv-pipeline-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
